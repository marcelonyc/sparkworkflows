{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark with MLRun example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook demonstrates how to execute a spark job with MLRun.\n",
    "\n",
    "Our spark job is a generic ETL job which pulls data from user-defined data sources, applies a SQL query on top of them, and writes the result to a user defined destination.\n",
    "\n",
    "The definition of the input-sources should be according to : https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader\n",
    "\n",
    "The definition of the output destination should be according to :\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "from mlrun import new_function, NewTask, mlconf, mount_v3io\n",
    "\n",
    "#Set the mlrun database/api\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment vars to be set by Nuclio\n",
    "PYTHON_SCRIPT = os.getenv('PYTHON_SCRIPT','/kv-to-parquet.py')\n",
    "V3IO_SCRIPT_PATH = os.getenv('V3IO_SCRIPT_PATH',os.getcwd().replace('/User','/v3io/'+os.getenv('V3IO_HOME')))\n",
    "SPARK_JOB_NAME = os.getenv('SPARK_JOB_NAME','my-spark-job') \n",
    "SPARK_SPEC_MEM = os.getenv('SPARK_SPEC_MEM','2g') \n",
    "SPARK_SPEC_CPU = os.getenv('SPARK_SPEC_CPU',1) \n",
    "SPARK_SPEC_REPLICAS = os.getenv('SPARK_SPEC_REPLICAS',1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the pyspark script path\n",
    "V3IO_SCRIPT_PATH = V3IO_SCRIPT_PATH+PYTHON_SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V3IO_SCRIPT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a task (job parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a task execution with parameters\n",
    "PARAMS = {}\n",
    "SPARK_TASK = NewTask(params=PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of the dpendency jars\n",
    "V3IO_JARS_PATH = '/igz/java/libs/'\n",
    "DEPS_JARS_LIST = [join(V3IO_JARS_PATH, f) for f in os.listdir(V3IO_JARS_PATH) \n",
    "                  if isfile(join(V3IO_JARS_PATH, f)) and f.startswith('v3io-') and f.endswith('.jar')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a job on the Kubernetes cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create MLRun function to run the spark-job on the kubernetes cluster\n",
    "serverless_spark_fn = new_function(kind='spark', image='urihoenig/spark-app:2.4.4-2.9.0-0.0.3', \n",
    "                                   command=f'local://{V3IO_SCRIPT_PATH}', name=SPARK_JOB_NAME).apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(serverless_spark_fn.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverless_spark_fn.spec.env.append({'name':'V3IO_HOME_URL','value':os.getenv(\"V3IO_HOME_URL\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverless_spark_fn.spec.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverless_spark_fn.with_limits(mem=SPARK_SPEC_MEM)\n",
    "serverless_spark_fn.with_requests(cpu=SPARK_SPEC_CPU)\n",
    "serverless_spark_fn.with_igz_spark(igz_version='2.8_b3506_20191217042239')\n",
    "#Set number of executors\n",
    "serverless_spark_fn.spec.replicas = SPARK_SPEC_REPLICAS\n",
    "\n",
    "serverless_spark_fn.run(SPARK_TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
